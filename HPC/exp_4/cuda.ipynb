{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "34d7vwdj8IdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acfd61e-a438-4e33-d091-10c1ab77cf93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-4l7omyvg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-4l7omyvg\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4290 sha256=a361185cc11c0d74dafe4788054b6e4f035268da88e1f6a3cbe50cc0f586c10e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tqe8hatt/wheels/bc/4e/e0/2d86bd15f671dbeb32144013f1159dba09757fde36dc51a963\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "# Set up CUDA\n",
        "#First Change runtime to GPU and run this cell\n",
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__\n",
        "void add(int* A, int* B, int* C, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void multiply(int* A, int* B, int* C, int size) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row < size && col < size) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < size; i++) {\n",
        "            sum += A[row * size + i] * B[i * size + col];\n",
        "        }\n",
        "        C[row * size + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void initializeVector(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        vector[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "void initializeMatrix(int* matrix, int size) {\n",
        "    for (int i = 0; i < size * size; i++) {\n",
        "        matrix[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "void printVector(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        printf(\"%d \", vector[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "void printMatrix(int* matrix, int size) {\n",
        "    for (int row = 0; row < size; row++) {\n",
        "        for (int col = 0; col < size; col++) {\n",
        "            printf(\"%d \", matrix[row * size + col]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 4;\n",
        "    cudaError_t err;\n",
        "\n",
        "    // -------------------- Vector Addition --------------------\n",
        "    int *A, *B, *C;\n",
        "    size_t vectorBytes = N * sizeof(int);\n",
        "\n",
        "    A = (int*)malloc(vectorBytes);\n",
        "    B = (int*)malloc(vectorBytes);\n",
        "    C = (int*)malloc(vectorBytes);\n",
        "\n",
        "    initializeVector(A, N);\n",
        "    initializeVector(B, N);\n",
        "\n",
        "    printf(\"Vector A: \");\n",
        "    printVector(A, N);\n",
        "    printf(\"Vector B: \");\n",
        "    printVector(B, N);\n",
        "\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    err = cudaMalloc(&d_A, vectorBytes);\n",
        "    err = cudaMalloc(&d_B, vectorBytes);\n",
        "    err = cudaMalloc(&d_C, vectorBytes);\n",
        "\n",
        "    err = cudaMemcpy(d_A, A, vectorBytes, cudaMemcpyHostToDevice);\n",
        "    err = cudaMemcpy(d_B, B, vectorBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    add<<<blocks, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"CUDA error (add): %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    err = cudaMemcpy(C, d_C, vectorBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Addition: \");\n",
        "    printVector(C, N);\n",
        "\n",
        "    free(A); free(B); free(C);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "\n",
        "    // -------------------- Matrix Multiplication --------------------\n",
        "    int *D, *E, *F;\n",
        "    size_t matrixBytes = N * N * sizeof(int);\n",
        "\n",
        "    D = (int*)malloc(matrixBytes);\n",
        "    E = (int*)malloc(matrixBytes);\n",
        "    F = (int*)malloc(matrixBytes);\n",
        "\n",
        "    initializeMatrix(D, N);\n",
        "    initializeMatrix(E, N);\n",
        "\n",
        "    printf(\"\\nMatrix D: \\n\");\n",
        "    printMatrix(D, N);\n",
        "    printf(\"Matrix E: \\n\");\n",
        "    printMatrix(E, N);\n",
        "\n",
        "    int *d_D, *d_E, *d_F;\n",
        "    err = cudaMalloc(&d_D, matrixBytes);\n",
        "    err = cudaMalloc(&d_E, matrixBytes);\n",
        "    err = cudaMalloc(&d_F, matrixBytes);\n",
        "\n",
        "    err = cudaMemcpy(d_D, D, matrixBytes, cudaMemcpyHostToDevice);\n",
        "    err = cudaMemcpy(d_E, E, matrixBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threads(2, 2);\n",
        "    dim3 blocksMat((N + threads.x - 1) / threads.x, (N + threads.y - 1) / threads.y);\n",
        "\n",
        "    multiply<<<blocksMat, threads>>>(d_D, d_E, d_F, N);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"CUDA error (multiply): %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    err = cudaMemcpy(F, d_F, matrixBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Multiplication: \\n\");\n",
        "    printMatrix(F, N);\n",
        "\n",
        "    free(D); free(E); free(F);\n",
        "    cudaFree(d_D); cudaFree(d_E); cudaFree(d_F);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "7P-5O1AmkYsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c202039-a162-4e75-c4d3-21b5e6ab772d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 vector_add.cu -o vector_add\n"
      ],
      "metadata": {
        "id": "d-U8QGwSkoTz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrMwulO-ktFa",
        "outputId": "da5e66b2-05c2-415e-d723-755183788020"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: 3 6 7 5 \n",
            "Vector B: 3 5 6 2 \n",
            "Addition: 6 11 13 7 \n",
            "\n",
            "Matrix D: \n",
            "9 1 2 7 \n",
            "0 9 3 6 \n",
            "0 6 2 6 \n",
            "1 8 7 9 \n",
            "\n",
            "Matrix E: \n",
            "2 0 2 3 \n",
            "7 5 9 2 \n",
            "2 8 9 7 \n",
            "3 6 1 2 \n",
            "\n",
            "Multiplication: \n",
            "50 63 52 57 \n",
            "87 105 114 51 \n",
            "64 82 78 38 \n",
            "99 150 146 86 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXpfByqHmkun",
        "outputId": "88646e0c-bf68-4597-8913-a4a95b1465a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May  3 19:24:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}